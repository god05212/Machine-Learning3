# Heart Attack Analysis & Prediction
## 심장마비 분석 및 예측하기
프로젝트 기간: 2024/02/06(화) ~ 2024/02/20(화)  
<br/>
## 개요
해당 프로젝트는 심장마비에 대한 분석과 예측을 목표로 합니다. 이를 위해 "Heart Attack Analysis & Prediction Dataset"이라는 데이터셋을 활용하였습니다. 이 데이터셋은 심장마비를 분류하는 데에 사용되는 데이터를 포함하고 있습니다.  
  
이 프로젝트는 심장마비라는 의료 분야에서 중요한 문제를 해결하고자 진행되었습니다. 심장마비는 심장 기능의 장애로 인해 발생하며 생명에 직결되는 심각한 상황입니다. 이러한 이유로 프로젝트를 통해 심장마비를 사전에 예측하고 그에 대한 조치를 취함으로써 환자의 생명을 보호하고 치료 효과를 극대화하고자 하였습니다. 또한 심장마비에 대한 분석과 예측 모델을 개발함으로써 몇 가지 이익이 기대됩니다.  
  
1. 심장마비 예측 모델을 통해 의료진은 환자의 위험 정도를 사전에 파악할 수 있어 조기 진단과 치료를 진행할 수 있습니다.  
2. 환자의 건강 상태와 위험 요인을 고려하여 개인 맞춤형 치료 계획을 수립할 수 있습니다. 이를 통해 치료의 효과를 극대화하고 부작용을 최소화할 수 있습니다.  
3. 심장마비 예측 모델을 활용하여 공중보건 정책 수립이 가능해지며, 예방과 조기 대응을 위한 전략을 구축할 수 있습니다.  
  
따라서, 의료 분야에서의 중요한 문제를 해결하고 의료진과 환자 모두에게 도움이 되고자 프로젝트를 진행하게 되었습니다.
<br/>
## 사용한 데이터셋
Heart Attack Analysis & Prediction Dataset: A dataset for heart attack classification
- RASHIK RAHMAN
- https://www.kaggle.com/rashikrahmanpritom
- https://www.kaggle.com/datasets/rashikrahmanpritom/heart-attack-analysis-prediction-dataset/data
<br/>

## 프로젝트 목록
1. 소개  
    1.1 데이터 사전 설명  
    1.2 작업 목표

2. 준비  
    2.1 필요한 패키지  
    2.2 데이터 로드  
    2.3 데이터 이해하기

3. 탐색적 데이터 분석  
    3.1 단변량 분석  
    3.2 이변량 분석

4. 데이터 전처리  
    4.1 탐색적 데이터 분석을 통한 결론 도출  
    4.2 필요한 패키지  
    4.3 모델에 적합한 특성 생성

5. 모델링  
    5.1 선형 분류기  
    5.2 트리 모델
  
<br/>

## 프로젝트 수행 과정
1. 데이터셋 크기 확인 및 구조 파악
    - read_csv 함수를 사용하여 데이터를 로드한 후, shape 속성을 통해 데이터셋의 크기를 확인합니다.
    - head() 함수를 사용하여 상위 5개 행을 출력하여 데이터의 구조를 파악합니다.
  

2. 범주형과 연속형 열 분리
    - 각 열의 고유한 값 개수를 확인하여 범주형과 연속형 열을 분리합니다.
  

3. 연속형 열에 대한 요약 통계량 확인
    - df[con_cols].describe()를 사용하여 연속형 열에 대한 요약 통계량을 확인합니다. 이를 통해 데이터의 분포와 기초 통계량을 파악할 수 있습니다.
  

4. 결측값 확인
    - df.isnull().sum()을 사용하여 결측값이 있는지 확인합니다. 여기서는 결측값이 없다고 확인되었습니다.
  

5. 범주형 변수에 대한 Count plot 생성
    - matplotlib과 seaborn 라이브러리를 사용하여 범주형 변수에 대한 Count plot을 생성합니다. 이를 통해 각 변수의 카테고리별 빈도수를 시각화하여 데이터의 분포를 확인합니다.
  

6. 연속형 변수에 대한 box plot 과 타겟 변수에 대한 Count plot 생성
    - 선택한 연속형 변수를 기준으로 box plot을 그려 분포와 이상치를 시각적으로 파악합니다.
    - 타겟 변수에 대한 Count plot을 생성하여 시각화합니다.
  

7. 연속형 변수 간의 상관 관계 분석과 시각화
    - df[con_cols].corr().transpose()를 사용하여 연속형 변수들의 상관 행렬을 계산합니다.
    - sns.heatmap() 함수를 사용하여 상관 행렬을 히트맵으로 시각화합니다. 히트맵의 색상은 상관 계수의 크기를 나타냅니다.
  

8. 데이터프레임의 산점도 히트맵 생성
    - df.corr() 함수를 사용하여 데이터프레임의 모든 특성 간의 상관 관계를 계산합니다.
    - sns.heatmap() 함수를 사용하여 상관 관계 행렬을 히트맵으로 시각화합니다. 각 셀에는 상관 계수가 표시되며, 숫자로 표시되도록 설정합니다.
  

9. 단일 변수에 대한 분석과 시각화
    - sns.kdeplot() 함수를 사용하여 연속형 변수의 타겟 변수에 따른 분포를 KDE 그래프로 시각화합니다.
    - sns.kdeplot() 함수를 사용하여 범주형 변수의 분포를 시각화합니다.
    - sns.pairplot() 함수를 사용하여 데이터프레임의 변수들 간의 상관 관계를 시각화합니다.

10. 데이터프레임(df)의 복사본(df1) 생성 및 카테고리컬 변수에 대한 원-핫 인코딩 처리
    - pd.get_dummies() 함수 활용하였습니다.
    - drop_first=True로 설정하여 과적합 및 변수 상관관계 감소하였습니다.
   
11. 특성과 타겟 정의 및 스케일링 처리
    - 특성과 타겟을 정의하고, RobustScaler를 인스턴스화하였습니다.
    - 연속형 특성인 con_cols에 대해 fit_transform()을 수행하여 X의 해당 열을 스케일링하였습니다.
    - 스케일링된 데이터의 일부를 확인하기 위해 X의 첫 5개 행을 출력하여 확인하였습니다.

12. 학습과 평가를 위해 데이터를 학습 데이터와 테스트 데이터로 분할
    - random_state 매개변수 설정으로 재현성 확보하였습니다.
    - test_size 매개변수로 20%의 비율로 테스트 데이터 설정하여 학습/테스트 데이터 균형 유지 및 충분한 테스트 데이터 확보하였습니다.

13. 분류 모델 학습 및 평가
    - SVM 모델: SVC 클래스를 사용하여 선형 커널을 가진 SVM 모델을 학습시키고, predict 메서드로 테스트 데이터의 예측값을 계산하고, accuracy_score 함수를 활용하여 테스트 정확도를 계산하였습니다.
    - SVM 하이퍼파라미터 튜닝: GridSearchCV를 활용하여 C와 gamma의 여러 조합을 시도하여 최적의 조합을 찾았으며, 최적의 하이퍼파라미터 조합은 searcher.best_params_에서 확인하였습니다. 이를 사용하여 테스트 데이터의 예측값과 실제값을 비교하여 테스트 정확도를 계산하였습니다.
    - 로지스틱 회귀 분석: LogisticRegression 클래스를 사용하여 모델을 학습시키고, predict_proba 메서드를 사용하여 테스트 데이터의 예측 확률을 계산하였습니다. argmax 함수를 활용하여 가장 높은 확률을 가진 클래스를 선택하여 예측값을 구한 후, 이를 사용하여 테스트 정확도를 계산하였습니다.

14. 로지스틱 회귀(Logistic Regression) 모델을 사용한 예측 확률 계산 및 ROC 곡선 그리기
    - 로지스틱 회귀 모델을 학습시키고 예측 확률 계산하기: logreg.predict_proba(X_test)를 호출하여 클래스 1에 대한 예측 확률을 계산하고, [:, 1]을 사용하여 클래스 1에 대한 예측 확률만 선택하였습니다.
    - ROC 곡선을 그리기 위해 FPR, TPR 및 임계값 계산하기: roc_curve(y_test, y_pred_prob)를 사용하여 실제 클래스 값인 y_test와 클래스 1에 대한 예측 확률인 y_pred_prob를 입력하여 False Positive Rate(FPR), True Positive Rate(TPR) 및 임계값(thresholds)을 계산하였습니다.
    - ROC 곡선 그래프 출력하기: plt.plot 함수를 사용하여 ROC 곡선을 그래프로 출력하였으며, 빨간색 선으로 표시하고 "Random"과 "Logistic Regression"을 범례에 표시하였습니다.

15. 의사결정 트리(Decision Tree), 랜덤 포레스트(Random Forest) 및 그래디언트 부스팅(Gradient Boosting) 분류기를 사용한 모델 학습 및 정확도 출력하기
    - 모델 객체를 생성한 후 .fit(X_train, y_train)를 사용하여 모델을 학습시키고, .predict(X_test)를 사용하여 테스트 데이터에 대한 예측값을 계산한 후, accuracy_score(y_test, y_pred)를 통해 예측 결과의 정확도를 출력하며 각 모델의 학습과 예측 과정을 수행하고, 테스트 데이터에 대한 정확도를 확인하였습니다.
<br/>

## 모델의 test dataset에 대한 accuracy (소숫점 다섯 째 자리에서 반올림) 
| Model | accuracy |
|:----------------------------------------|:-------|
| Support Vector Machines                 | 0.8689 |
| Hyperparameter tuning of SVC            | 0.9016 |
| Logistic Regression                     | 0.9016 |
| Decision Tree                           | 0.7869 |
| Random Forest                           | 0.7869 |
| Gradient Boosting Classifier            | 0.8689 |
<br/>

## 최종 모델
Logistic Regression
- test dataset에 대한 결과
  - accuracy: 약 0.9016
<br/>

## 결론
**EDA를 통한 결론 도출**  
1. 데이터에는 결측값(NaN)이 없습니다.
2. 모든 연속 변수에는 특정 이상치(outlier)가 있습니다.
3. 데이터에서 sex = 1인 사람의 수는 sex = 0인 사람의 수보다 두 배 이상 많습니다.
4. 히트맵을 통해 연속 변수 간에는 명확한 선형 상관 관계가 보이지 않습니다.
5. 산점도 히트맵 행렬을 통해 출력과 cp, thalachh, slp 사이에 어느 정도 상관 관계가 있을 수 있다는 것을 시사합니다.
6. 나이가 많을수록 심장 발작 위험이 높을 것으로 직관적으로 생각할 수 있지만, 나이에 따른 출력의 분포 그래프를 보면 그렇지 않다는 것을 알 수 있습니다.
7. 최대 심박수(thalachh)에 따른 출력의 분포 그래프를 보면, 최대 심박수가 높은 사람일수록 심장 발작 위험이 더 높다는 것을 알 수 있습니다.
8. 이전 최저 수치(oldpeak)에 따른 출력의 분포 그래프를 보면, 이전 최저 수치 낮은 사람일수록 심장 발작 위험이 더 높다는 것을 알 수 있습니다.
9. 3.2.4 그래프는 다음과 같은 내용을 보여줍니다.
    - 비협심성 통증(cp = 2)을 가진 사람은 심장 발작 위험이 높습니다.
    - 주요 혈관이 없는 사람(caa = 0)은 심장 발작 위험이 높습니다.
    - 성별이 1인 사람은 심장 발작 위험이 더 높습니다.
    - thall = 2인 사람은 심장 발작 위험이 훨씬 높습니다.
    - 운동 유발 협심증이 없는 사람(exng = 0)은 심장 발작 위험이 더 높습니다.

EDA 결과를 종합하면 심장마비 위험과 관련된 여러 변수들이 있음을 알 수 있습니다. 성별, 협심증 여부, 혈관 상태 등이 심장마비 위험에 영향을 미친다는 것을 확인할 수 있습니다. 특히, 최대 심박수(thalachh)와 이전 최저 수치(oldpeak)가 심장 발작과 관련된 중요한 변수임을 확인할 수 있습니다. EDA를 통해 이러한 변수들이 심장마비 위험을 예측하는데 중요한 역할을 할 수 있음을 알 수 있으며, 이러한 정보는 심장 질환 예방 및 관리에 도움이 될 수 있습니다.

따라서 추가적인 분석과 모델링을 통해 이러한 변수들을 활용하여 심장 질환 예측 모델을 구축하는 것이 의미있을 것으로 보입니다.
