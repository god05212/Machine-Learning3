# Heart Attack Analysis & Prediction
## 심장마비 분석 및 예측하기
프로젝트 기간: 2024/02/06(화) ~ 2024/02/20(화)  
<br/>
## 개요
해당 프로젝트는 심장마비에 대한 분석과 예측을 목표로 합니다. 이를 위해 "Heart Attack Analysis & Prediction Dataset"이라는 데이터셋을 활용하였습니다. 이 데이터셋은 심장마비를 분류하는 데에 사용되는 데이터를 포함하고 있습니다.  
  
이 프로젝트는 심장마비라는 의료 분야에서 중요한 문제를 해결하고자 진행되었습니다. 심장마비는 심장 기능의 장애로 인해 발생하며 생명에 직결되는 심각한 상황입니다. 이러한 이유로 프로젝트를 통해 심장마비를 사전에 예측하고 그에 대한 조치를 취함으로써 환자의 생명을 보호하고 치료 효과를 극대화하고자 하였습니다. 또한 심장마비에 대한 분석과 예측 모델을 개발함으로써 몇 가지 이익이 기대됩니다.  
  
1. 심장마비 예측 모델을 통해 의료진은 환자의 위험 정도를 사전에 파악할 수 있어 조기 진단과 치료를 진행할 수 있습니다.  
2. 환자의 건강 상태와 위험 요인을 고려하여 개인 맞춤형 치료 계획을 수립할 수 있습니다. 이를 통해 치료의 효과를 극대화하고 부작용을 최소화할 수 있습니다.  
3. 심장마비 예측 모델을 활용하여 공중보건 정책 수립이 가능해지며, 예방과 조기 대응을 위한 전략을 구축할 수 있습니다.  
  
따라서, 의료 분야에서의 중요한 문제를 해결하고 의료진과 환자 모두에게 도움이 되고자 프로젝트를 진행하게 되었습니다.
<br/>
## 사용한 데이터셋
Heart Attack Analysis & Prediction Dataset: A dataset for heart attack classification
- RASHIK RAHMAN
- https://www.kaggle.com/rashikrahmanpritom
- https://www.kaggle.com/datasets/rashikrahmanpritom/heart-attack-analysis-prediction-dataset/data
<br/>

## 프로젝트 목록
1. 소개  
    1.1 데이터 사전 설명  
    1.2 작업 목표

2. 준비  
    2.1 필요한 패키지  
    2.2 데이터 로드  
    2.3 데이터 이해하기

3. 탐색적 데이터 분석  
    3.1 단변량 분석  
    3.2 이변량 분석

4. 데이터 전처리  
    4.1 탐색적 데이터 분석을 통한 결론 도출  
    4.2 필요한 패키지  
    4.3 모델에 적합한 특성 생성

5. 모델링  
    5.1 선형 분류기  
    5.2 트리 모델
  
<br/>

## 프로젝트 수행 과정
1. 데이터셋 크기 확인 및 구조 파악
    - read_csv 함수를 사용하여 데이터를 로드한 후, shape 속성을 통해 데이터셋의 크기를 확인합니다.
    - head() 함수를 사용하여 상위 5개 행을 출력하여 데이터의 구조를 파악합니다.
  

2. 범주형과 연속형 열 분리
    - 각 열의 고유한 값 개수를 확인하여 범주형과 연속형 열을 분리합니다.
  

3. 연속형 열에 대한 요약 통계량 확인
    - df[con_cols].describe()를 사용하여 연속형 열에 대한 요약 통계량을 확인합니다. 이를 통해 데이터의 분포와 기초 통계량을 파악할 수 있습니다.
  

4. 결측값 확인
    - df.isnull().sum()을 사용하여 결측값이 있는지 확인합니다. 여기서는 결측값이 없다고 확인되었습니다.
  

5. 범주형 변수에 대한 Count plot 생성
    - matplotlib과 seaborn 라이브러리를 사용하여 범주형 변수에 대한 Count plot을 생성합니다. 이를 통해 각 변수의 카테고리별 빈도수를 시각화하여 데이터의 분포를 확인합니다.
  

6. 연속형 변수에 대한 box plot 및 타겟 변수에 대한 Count plot 생성
    - 선택한 연속형 변수를 기준으로 box plot을 그려 분포와 이상치를 시각적으로 파악합니다.
    - 타겟 변수에 대한 Count plot을 생성하여 시각화합니다.
  

7. 연속형 변수 간의 상관 관계 분석과 시각화
    - df[con_cols].corr().transpose()를 사용하여 연속형 변수들의 상관 행렬을 계산합니다.
    - sns.heatmap() 함수를 사용하여 상관 행렬을 히트맵으로 시각화합니다. 히트맵의 색상은 상관 계수의 크기를 나타냅니다.
  

8. 데이터프레임의 산점도 히트맵 생성
    - df.corr() 함수를 사용하여 데이터프레임의 모든 특성 간의 상관 관계를 계산합니다.
    - sns.heatmap() 함수를 사용하여 상관 관계 행렬을 히트맵으로 시각화합니다. 각 셀에는 상관 계수가 표시되며, 숫자로 표시되도록 설정합니다.
  

9. 단일 변수에 대한 분석과 시각화
    - sns.kdeplot() 함수를 사용하여 연속형 변수의 타겟 변수에 따른 분포를 KDE 그래프로 시각화합니다.
    - sns.kdeplot() 함수를 사용하여 범주형 변수의 분포를 시각화합니다.
    - sns.pairplot() 함수를 사용하여 데이터프레임의 변수들 간의 상관 관계를 시각화합니다.


- 데이터프레임(df)의 복사본인 df1을 생성하였습니다. 인코딩과 스케일링이 필요한 열을 정의하고, pd.get_dummies() 함수를 사용하여 cat_cols에 해당하는 열을 대상으로 원-핫 인코딩을 수행하였습니다. 첫 번째 열은 나머지 더미 변수들의 합으로 표현할 수 있어서 과적합을 방지하고 변수 간의 상관관계를 줄여 모델이 독립적인 변수들을 더 잘 학습할 수 있도록 모델의 성능을 향상시키기 위해 drop_first=True로 설정하여 카테고리컬 열이 인코딩된 데이터프레임 df1이 생성하였습니다.
- 특성과 타겟 정의하고, RobustScaler를 인스턴스화하고, 스케일링이 필요한 연속형 특성인 con_cols에 대해 fit_transform을 수행하여 X의 해당 열을 스케일링하고, X의 첫 5개 행을 출력하여 스케일링된 데이터의 일부를 확인하였습니다.
- 데이터를 학습과 평가에 사용하기 위해 학습 데이터와 테스트 데이터로 나눴습니다. 데이터를 무작위로 분할하기 때문에, random_state 매개변수를 설정하여 매번 동일한 분할 결과를 얻게 하였습니다. 이를 통해 실험의 재현성을 확보하고 일관된 결과를 얻고자 하였습니다. 또한 test_size 매개변수를 통해 전체 데이터 중 테스트 데이터의 비율을 조정할 수 있는데 학습 데이터와 테스트 데이터 간의 균형을 유지하면서도 충분한 테스트 데이터를 확보할 수 있는 좋은 균형점인 0.2 (20%)의 비율로 테스트 데이터를 설정하였습니다.
- 분류 모델을 사용하여 데이터를 분석하고 예측하는 작업을 수행하기 위해 여러 알고리즘 중에서 Support Vector Machines (SVM)와 로지스틱 회귀 분석을 사용하였습니다.
- SVM은 SVC 클래스를 사용하여 선형 커널을 가진 SVM 모델을 만들고, fit 메서드를 사용하여 모델을 학습시켰습니다. 학습된 모델을 사용하여 predict 메서드를 호출하여 테스트 데이터의 예측값을 구하고, accuracy_score 함수를 사용하여 예측값과 실제값을 비교하여 테스트 정확도를 계산하였습니다.
- 또한, SVM 하이퍼파라미터 튜닝을 위해 GridSearchCV를 사용하였습니다. C와 gamma라는 하이퍼파라미터들의 여러 조합을 시도하여 최적의 조합을 찾고, 최적의 하이퍼파라미터 조합은 searcher.best_params_에서 확인하고, 이를 사용하여 테스트 데이터의 예측값과 실제값을 비교하여 테스트 정확도를 계산하였습니다.
- 로지스틱 회귀 분석은 LogisticRegression 클래스를 사용하여 모델을 만들고, fit 메서드를 사용하여 모델을 학습시켰습니다. 그리고 학습된 모델을 사용해서 predict_proba 메서드를 호출하여 테스트 데이터의 예측 확률을 계산하고, argmax 함수를 사용하여 가장 높은 확률을 가진 클래스를 선택하여 예측값을 구한 후 이를 사용하여 테스트 정확도를 계산하였습니다.
- 로지스틱 회귀 모델을 사용하여 클래스 1에 대한 예측 확률을 계산하고, 이를 기반으로 ROC 곡선을 그리는 과정을 보여주었습니다. y_pred_prob = logreg.predict_proba(X_test)[:,1]: logreg라는 로지스틱 회귀 모델을 사용하여 X_test 데이터에 대한 예측 확률을 계산하고, predict_proba 함수는 각 클래스에 대한 예측 확률을 반환하는데, [:,1]을 사용하여 클래스 1에 대한 예측 확률만 선택하였습니다.
- fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob): roc_curve 함수를 사용하여 ROC 곡선을 그리기 위해 필요한 False Positive Rate(FPR), True Positive Rate(TPR), 그리고 임계값(thresholds)을 계산하였습니다. 이때, y_test는 실제 클래스 값이고, y_pred_prob는 클래스 1에 대한 예측 확률입니다.
- plt.plot 함수를 사용하여 ROC 곡선을 그래프로 출력하였습니다. [0, 1] 범위의 x축과 [0, 1] 범위의 y축을 가지는 선을 그리는데 검은색 점선의 색상을 빨간색으로 지정하였습니다. 또한, label을 사용하여 범례에 "Random"과 "Logistic Regression"을 표시하였습니다. plt.xlabel, plt.ylabel, plt.title 함수를 사용하여 각각 x축, y축, 그리고 그래프 제목을 설정하고 plt.legend 함수를 사용하여 범례를 표시한 후, plt.show 함수를 사용하여 그래프를 출력하였습니다. 이 코드를 실행하면 로지스틱 회귀 모델의 예측 확률을 기반으로 한 ROC 곡선이 그려집니다. ROC 곡선은 분류 모델의 성능을 평가하는데 사용되며, x축은 FPR(False Positive Rate), y축은 TPR(True Positive Rate)를 나타냅니다.
- 의사결정 트리, 랜덤 포레스트, 그래디언트 부스팅 분류기를 사용하여 모델을 학습하고 예측 결과의 정확도를 출력하였습니다. 먼저, 의사결정 트리 모델 객체를 생성한 후 dt.fit(X_train, y_train)를 통해 모델을 학습하였습니다. 그리고 dt.predict(X_test)를 사용하여 테스트 데이터에 대한 예측값을 계산하고, accuracy_score(y_test, y_pred)를 통해 예측 결과의 정확도를 출력하였습니다.
- 다음으로, 랜덤 포레스트 모델 객체를 생성한 후 rf.fit(X_train, y_train)를 통해 모델을 학습한 후 마찬가지로 dt.predict(X_test)를 사용하여 테스트 데이터에 대한 예측값을 계산하고, accuracy_score(y_test, y_pred)를 통해 예측 결과의 정확도를 출력하였습니다.
- 마지막으로, 그래디언트 부스팅 분류기 모델 객체를 생성한 후 gbt.fit(X_train, y_train)를 통해 모델을 학습하고, 마찬가지로 gbt.predict(X_test)를 사용하여 테스트 데이터에 대한 예측값을 계산한 후 accuracy_score(y_test, y_pred)를 통해 예측 결과의 정확도를 출력하며 각 모델의 학습과 예측 과정을 수행하고, 테스트 데이터에 대한 정확도를 확인하였습니다.
<br/>

## 모델의 test dataset에 대한 accuracy (소숫점 다섯 째 자리에서 반올림) 
| Model | accuracy |
|:----------------------------------------|:-------|
| Support Vector Machines                 | 0.8689 |
| Hyperparameter tuning of SVC            | 0.9016 |
| Logistic Regression                     | 0.9016 |
| Decision Tree                           | 0.7869 |
| Random Forest                           | 0.7869 |
| Gradient Boosting Classifier            | 0.8689 |
<br/>

## 최종 모델
Logistic Regression
- test dataset에 대한 결과
  - accuracy: 약 0.9016
<br/>

## 결론
**EDA를 통한 결론 도출**  
1. 데이터에는 결측값(NaN)이 없습니다.
2. 모든 연속 변수에는 특정 이상치(outlier)가 있습니다.
3. 데이터에서 sex = 1인 사람의 수는 sex = 0인 사람의 수보다 두 배 이상 많습니다.
4. 히트맵을 통해 연속 변수 간에는 명확한 선형 상관 관계가 보이지 않습니다.
5. 산점도 히트맵 행렬을 통해 출력과 cp, thalachh, slp 사이에 어느 정도 상관 관계가 있을 수 있다는 것을 시사합니다.
6. 나이가 많을수록 심장 발작 위험이 높을 것으로 직관적으로 생각할 수 있지만, 나이에 따른 출력의 분포 그래프를 보면 그렇지 않다는 것을 알 수 있습니다.
7. 최대 심박수(thalachh)에 따른 출력의 분포 그래프를 보면, 최대 심박수가 높은 사람일수록 심장 발작 위험이 더 높다는 것을 알 수 있습니다.
8. 이전 최저 수치(oldpeak)에 따른 출력의 분포 그래프를 보면, 이전 최저 수치 낮은 사람일수록 심장 발작 위험이 더 높다는 것을 알 수 있습니다.
9. 3.2.4 그래프는 다음과 같은 내용을 보여줍니다.
    - 비협심 흉통(cp = 2)을 가진 사람은 심장 발작 위험이 높습니다.
    - 주요 혈관이 없는 사람(caa = 0)은 심장 발작 위험이 높습니다.
    - 성별이 1인 사람은 심장 발작 위험이 더 높습니다.
    - thall = 2인 사람은 심장 발작 위험이 훨씬 높습니다.
    - 운동 유발 협심증이 없는 사람(exng = 0)은 심장 발작 위험이 더 높습니다.
