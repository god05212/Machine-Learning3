{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP49eXTeUPJtxtr1ekc6szE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/god05212/VGG19/blob/main/VGG19.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 사용한 데이터셋\n",
        "> Face Mask Detection: 853 images belonging to 3 classes\n",
        "\n",
        "- Larxel\n",
        "- https://www.kaggle.com/andrewmvd\n",
        "- https://www.kaggle.com/datasets/andrewmvd/face-mask-detection"
      ],
      "metadata": {
        "id": "3SLCRojo5Ye_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Basic Exploration"
      ],
      "metadata": {
        "id": "u0ix3wAJ7Wyp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> 필요한 라이브러리를 import하고 데이터를 불러옵니다."
      ],
      "metadata": {
        "id": "q_xrKJ587aEK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 필요한 라이브러리 import\n",
        "import numpy as np # 선형대수\n",
        "import cv2\n",
        "from scipy.spatial import distance\n",
        "from keras.applications.vgg19 import VGG19\n",
        "from keras.applications.vgg19 import preprocess_input\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Flatten, Dense\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "YgZ1HlL97mUA"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Read dataset"
      ],
      "metadata": {
        "id": "zs_sC2fC7uOm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Bi0q-LF76Cs",
        "outputId": "cca20ec6-4700-46ec-d4d9-9820612cb3df"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Haar Cascade 얼굴 검출 모델 로드\n",
        "face_model = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')"
      ],
      "metadata": {
        "id": "6MJYGKFL_wjy"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 사전 훈련된 VGG19 모델 로드\n",
        "vgg19 = VGG19(weights='imagenet', include_top=False, input_shape=(128, 128, 3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PJIPYWc_LL6d",
        "outputId": "7725aa54-1bd6-4547-8b34-fd20a62b1aa8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "80134624/80134624 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# VGG19 모델의 레이어를 동결\n",
        "for layer in vgg19.layers:\n",
        "    layer.trainable = False"
      ],
      "metadata": {
        "id": "VOJ0wPOYLVA7"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 마스크 감지를 위한 Sequential 모델 생성\n",
        "model = Sequential()\n",
        "model.add(vgg19)\n",
        "model.add(Flatten())\n",
        "model.add(Dense(2, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "sQPUOpJ-Lgdj"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 컴파일\n",
        "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "4OcXAJwHLjBQ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import xml.etree.ElementTree as ET\n",
        "data_dir = '/content/drive/MyDrive/archive (2)'\n",
        "image_files = []  # 이미지 파일 경로를 저장할 리스트\n",
        "labels = []  # 레이블 데이터를 저장할 리스트"
      ],
      "metadata": {
        "id": "Xuq_uoYHLmJl"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for filename in os.listdir(data_dir):\n",
        "    if filename.endswith(\".png\"):\n",
        "        # 이미지 파일 로드\n",
        "        image_path = os.path.join(data_dir, filename)\n",
        "        image_files.append(image_path)\n",
        "\n",
        "        # 레이블 데이터 파일 경로 생성\n",
        "        xml_filename = filename.replace(\".png\", \".xml\")\n",
        "        xml_path = os.path.join(data_dir, xml_filename)\n",
        "\n",
        "        if os.path.exists(xml_path):  # 해당 이미지에 대한 레이블 데이터 파일이 존재하는 경우에만 추가\n",
        "            # XML 파일로부터 레이블 데이터 추출\n",
        "            tree = ET.parse(xml_path)\n",
        "            root = tree.getroot()\n",
        "            label = root.find(\"label\").text\n",
        "            labels.append(label)"
      ],
      "metadata": {
        "id": "-KSislVFL-tt"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "data_size = len(image_files)\n",
        "\n",
        "# 데이터셋 크기에 따라 분할 비율 조정\n",
        "train_ratio = 0.7  # 70% for training\n",
        "val_ratio = 0.15  # 15% for validation\n",
        "test_ratio = 0.15  # 15% for testing\n",
        "\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(image_files, labels, test_size=(1 - train_ratio), random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, test_size=(test_ratio / (test_ratio + val_ratio)), random_state=42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        },
        "id": "PZNHRLGCMCXK",
        "outputId": "61cda111-5d89-4daa-d0c9-a08fac5761c1"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-c1dbb207f20d>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mtest_ratio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.15\u001b[0m  \u001b[0;31m# 15% for testing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_temp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_temp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_files\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtrain_ratio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_temp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_ratio\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtest_ratio\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mval_ratio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2560\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2561\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2562\u001b[0;31m     n_train, n_test = _validate_shuffle_split(\n\u001b[0m\u001b[1;32m   2563\u001b[0m         \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault_test_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2564\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m_validate_shuffle_split\u001b[0;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[1;32m   2234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2235\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mn_train\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2236\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m   2237\u001b[0m             \u001b[0;34m\"With n_samples={}, test_size={} and train_size={}, the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2238\u001b[0m             \u001b[0;34m\"resulting train set will be empty. Adjust any of the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: With n_samples=0, test_size=0.30000000000000004 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UzpiSXg04og0"
      },
      "outputs": [],
      "source": [
        "# 데이터 디렉토리 설정\n",
        "train_dir = '훈련_디렉토리_경로'\n",
        "val_dir = '검증_디렉토리_경로'\n",
        "test_dir = '테스트_디렉토리_경로'\n",
        "\n",
        "# 훈련 및 검증 데이터에 대한 데이터 증강 생성\n",
        "train_datagen = ImageDataGenerator(rescale=1.0/255, horizontal_flip=True, zoom_range=0.2, shear_range=0.2)\n",
        "val_datagen = ImageDataGenerator(rescale=1.0/255)\n",
        "\n",
        "# 데이터 제너레이터 생성\n",
        "train_generator = train_datagen.flow_from_directory(directory=train_dir, target_size=(128, 128), class_mode='categorical', batch_size=32)\n",
        "val_generator = val_datagen.flow_from_directory(directory=val_dir, target_size=(128, 128), class_mode='categorical', batch_size=32)\n",
        "\n",
        "# 모델 훈련\n",
        "history = model.fit(x=train_generator, epochs=20, validation_data=val_generator)\n",
        "\n",
        "# 테스트 데이터로 모델 평가\n",
        "test_datagen = ImageDataGenerator(rescale=1.0/255)\n",
        "test_generator = test_datagen.flow_from_directory(directory=test_dir, target_size=(128, 128), class_mode='categorical', batch_size=32)\n",
        "test_results = model.evaluate(test_generator)\n",
        "\n",
        "# 마스크 감지를 위한 테스트 이미지 로드\n",
        "sample_mask_img = cv2.imread('테스트_이미지_경로')\n",
        "sample_mask_img = cv2.resize(sample_mask_img, (128, 128))\n",
        "sample_mask_img = np.expand_dims(sample_mask_img, axis=0) / 255.0\n",
        "\n",
        "# 마스크 감지 실행\n",
        "mask_result = model.predict(sample_mask_img)\n",
        "\n",
        "# 사회적 거리두기 위반을 검출할 MIN_DISTANCE 정의\n",
        "MIN_DISTANCE = 130\n",
        "\n",
        "# 사회적 거리두기 위반을 검출할 이미지 로드\n",
        "img = cv2.imread('이미지_경로')\n",
        "img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "faces = face_model.detectMultiScale(img_gray, scaleFactor=1.1, minNeighbors=4)\n",
        "\n",
        "if len(faces) >= 2:\n",
        "    label = [0 for i in range(len(faces)]\n",
        "    for i in range(len(faces)-1):\n",
        "        for j in range(i+1, len(faces)):\n",
        "            dist = distance.euclidean(faces[i][:2], faces[j][:2])\n",
        "            if dist < MIN_DISTANCE:\n",
        "                label[i] = 1\n",
        "                label[j] = 1\n",
        "\n",
        "    new_img = img.copy()\n",
        "    for i in range(len(faces):\n",
        "        (x, y, w, h) = faces[i]\n",
        "        crop = new_img[y:y+h, x:x+w]\n",
        "        crop = cv2.resize(crop, (128, 128))\n",
        "        crop = np.expand_dims(crop, axis=0) / 255.0\n",
        "        mask_result = model.predict(crop)\n",
        "        mask_label = \"MASK\" if mask_result[0][0] > mask_result[0][1] else \"NO MASK\"\n",
        "        color = (0, 255, 0) if label[i] == 0 else (255, 0, 0)\n",
        "        cv2.putText(new_img, mask_label, (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
        "        cv2.rectangle(new_img, (x, y), (x+w, y+h), color, 1)\n",
        "\n",
        "    cv2.imshow(\"사회적 거리두기 및 마스크 검출\", new_img)\n",
        "    cv2.waitKey(0)\n",
        "else:\n",
        "    print(\"검출된 얼굴 수가 2개 미만입니다\")\n",
        "\n",
        "# 모델 저장\n",
        "model.save('masknet.h5')"
      ]
    }
  ]
}