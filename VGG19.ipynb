{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPJgO1jhtx6qL3aMgf5QMaq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/god05212/VGG19/blob/main/VGG19.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UzpiSXg04og0"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "from scipy.spatial import distance\n",
        "from keras.applications.vgg19 import VGG19\n",
        "from keras.applications.vgg19 import preprocess_input\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Flatten, Dense\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Haar Cascade 얼굴 검출 모델 로드\n",
        "face_model = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
        "\n",
        "# 사전 훈련된 VGG19 모델 로드\n",
        "vgg19 = VGG19(weights='imagenet', include_top=False, input_shape=(128, 128, 3))\n",
        "\n",
        "# VGG19 모델의 레이어를 동결\n",
        "for layer in vgg19.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# 마스크 감지를 위한 Sequential 모델 생성\n",
        "model = Sequential()\n",
        "model.add(vgg19)\n",
        "model.add(Flatten())\n",
        "model.add(Dense(2, activation='sigmoid'))\n",
        "\n",
        "# 모델 컴파일\n",
        "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "# 데이터 디렉토리 설정\n",
        "train_dir = '훈련_디렉토리_경로'\n",
        "val_dir = '검증_디렉토리_경로'\n",
        "test_dir = '테스트_디렉토리_경로'\n",
        "\n",
        "# 훈련 및 검증 데이터에 대한 데이터 증강 생성\n",
        "train_datagen = ImageDataGenerator(rescale=1.0/255, horizontal_flip=True, zoom_range=0.2, shear_range=0.2)\n",
        "val_datagen = ImageDataGenerator(rescale=1.0/255)\n",
        "\n",
        "# 데이터 제너레이터 생성\n",
        "train_generator = train_datagen.flow_from_directory(directory=train_dir, target_size=(128, 128), class_mode='categorical', batch_size=32)\n",
        "val_generator = val_datagen.flow_from_directory(directory=val_dir, target_size=(128, 128), class_mode='categorical', batch_size=32)\n",
        "\n",
        "# 모델 훈련\n",
        "history = model.fit(x=train_generator, epochs=20, validation_data=val_generator)\n",
        "\n",
        "# 테스트 데이터로 모델 평가\n",
        "test_datagen = ImageDataGenerator(rescale=1.0/255)\n",
        "test_generator = test_datagen.flow_from_directory(directory=test_dir, target_size=(128, 128), class_mode='categorical', batch_size=32)\n",
        "test_results = model.evaluate(test_generator)\n",
        "\n",
        "# 마스크 감지를 위한 테스트 이미지 로드\n",
        "sample_mask_img = cv2.imread('테스트_이미지_경로')\n",
        "sample_mask_img = cv2.resize(sample_mask_img, (128, 128))\n",
        "sample_mask_img = np.expand_dims(sample_mask_img, axis=0) / 255.0\n",
        "\n",
        "# 마스크 감지 실행\n",
        "mask_result = model.predict(sample_mask_img)\n",
        "\n",
        "# 사회적 거리두기 위반을 검출할 MIN_DISTANCE 정의\n",
        "MIN_DISTANCE = 130\n",
        "\n",
        "# 사회적 거리두기 위반을 검출할 이미지 로드\n",
        "img = cv2.imread('이미지_경로')\n",
        "img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "faces = face_model.detectMultiScale(img_gray, scaleFactor=1.1, minNeighbors=4)\n",
        "\n",
        "if len(faces) >= 2:\n",
        "    label = [0 for i in range(len(faces)]\n",
        "    for i in range(len(faces)-1):\n",
        "        for j in range(i+1, len(faces)):\n",
        "            dist = distance.euclidean(faces[i][:2], faces[j][:2])\n",
        "            if dist < MIN_DISTANCE:\n",
        "                label[i] = 1\n",
        "                label[j] = 1\n",
        "\n",
        "    new_img = img.copy()\n",
        "    for i in range(len(faces):\n",
        "        (x, y, w, h) = faces[i]\n",
        "        crop = new_img[y:y+h, x:x+w]\n",
        "        crop = cv2.resize(crop, (128, 128))\n",
        "        crop = np.expand_dims(crop, axis=0) / 255.0\n",
        "        mask_result = model.predict(crop)\n",
        "        mask_label = \"MASK\" if mask_result[0][0] > mask_result[0][1] else \"NO MASK\"\n",
        "        color = (0, 255, 0) if label[i] == 0 else (255, 0, 0)\n",
        "        cv2.putText(new_img, mask_label, (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
        "        cv2.rectangle(new_img, (x, y), (x+w, y+h), color, 1)\n",
        "\n",
        "    cv2.imshow(\"사회적 거리두기 및 마스크 검출\", new_img)\n",
        "    cv2.waitKey(0)\n",
        "else:\n",
        "    print(\"검출된 얼굴 수가 2개 미만입니다\")\n",
        "\n",
        "# 모델 저장\n",
        "model.save('masknet.h5')"
      ]
    }
  ]
}